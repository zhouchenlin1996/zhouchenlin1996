<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects | Chenlin Zhou</title>
    <link>/project/</link>
      <atom:link href="/project/index.xml" rel="self" type="application/rss+xml" />
    <description>Projects</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>©</copyright><lastBuildDate>Wed, 27 Apr 2016 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url>
      <title>Projects</title>
      <link>/project/</link>
    </image>
    
    <item>
      <title>Intelligent Detection Robot System for Refrigerator‘s Tubular Solder Joints Based on Computer Vision</title>
      <link>/project/detection/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>/project/detection/</guid>
      <description>&lt;p&gt;We developed a intelligent detection robot system for refrigerator‘s tubular solder joints based on computer vision. The system can realize the automatic quality inspection of the refrigerator&amp;rsquo;s tubular solder  joints on the industrial assembly line with high-precision and real-time performance. Before this, the refrigerator&amp;rsquo;s tubular solder joint detection in the industry is by traditional manual detection.&lt;/p&gt;
&lt;p&gt;Tubular solder joint detection is an important and challenging issue in the industry, due to the illegible objects, rarely collected datasets and requiring high-precision and real-time performance for positioning and angle estimation. In this article, we propose an Attention integrated and Cross-spatial feature fused Rotation Network (ACR-Net) for tubular solder joint detection, which consists of a new feature extraction network named ECA-CSPDarknet44, a cross-spatial feature fusion network (CFFN), and a bin-based rotation detection network (BRDN). The proposed network can efficiently detect oriented tubular solder joints with high-precision and real-time performance. ECA-CSPDarknet44 with attention mechanism was presented, which can adaptively guide the network to learn important features of tubular solder joints, significantly improving the ability of feature extraction. By integrating multiscale global features and multiscale local region features, CFFN can enhance the network&amp;rsquo;s ability to express the characteristics of tubular solder joints. Meanwhile, BRDN is proposed for oriented bounding box regression through a decoupling approach, which regresses target parameters efficiently and accurately with little increasing of model complexity. Finally, we establish a tubular solder joint dataset and conduct sufficient experiments to verify the effectiveness of our method. Our proposed ACR-Net achieves 98.8% mAP with 31.3 frames per second (FPSs) on the dataset, meeting the high-precision and real-time requirements of industrial systems.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Research on “Push-grasp-suction” Integrated Dexterous Picking of Ambidextrous robot</title>
      <link>/project/robot-picking/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>/project/robot-picking/</guid>
      <description>&lt;p&gt;slides = &amp;quot;&amp;quot;&lt;/p&gt;
&lt;p&gt;Object picking in cluttered scenes is a widely investigated field of robot manipulation, however, ambidextrous robot picking is still an important and challenging issue. We found the fusion of different prehensile actions (grasp and suction) can expand the range of objects that can be picked by robot, and the fusion of prehensile action and nonprehensile action (push) can expand the picking space of  ambidextrous robot. In this paper, we propose a &amp;ldquo;Push-Grasp-Suction&amp;rdquo; (PGS)  integrated network for ambidextrous robot picking through the fusion of different prehensile actions and the fusion of prehensile action and nonprehensile aciton. The prehensile branch of PGS takes point clouds as input, and the 6-DoF picking configuration of grasp and suction in cluttered scenes are generated by multi-task point cloud learning. The nonprehensile branch with depth image input generates instance segmentation map and push configuration, cooperating with the prehensile actions to complete the picking of objects out of single-arm space. PGS generalizes well in real scene and achieves state-of-the-art picking performance.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
